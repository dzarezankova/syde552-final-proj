{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c719b3ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T01:02:57.502263Z",
     "start_time": "2024-04-13T01:02:11.192680Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, torch, shutil, numpy as np, pandas as pd\n",
    "from glob import glob; from PIL import Image\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import optim\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T01:03:28.699916Z",
     "start_time": "2024-04-13T01:03:27.564246Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040\n",
      "58\n",
      "1850\n",
      "{'Topwear': 0, 'Shoes': 1, 'Bags': 2, 'Bottomwear': 3, 'Watches': 4, 'Innerwear': 5, 'Jewellery': 6, 'Eyewear': 7, 'Fragrance': 8, 'Sandal': 9}\n"
     ]
    }
   ],
   "source": [
    "root = \"e-commerce-products-images\"\n",
    "mean, std, im_size = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 224\n",
    "tfs = T.Compose([T.Resize((im_size, im_size)), T.ToTensor(), T.Normalize(mean = mean, std = std)])\n",
    "tr_dl, val_dl, ts_dl, classes = data.get_dls(root = root, transformations = tfs, bs = 32)\n",
    "\n",
    "print(len(tr_dl)); print(len(val_dl)); print(len(ts_dl)); print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b338e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T01:03:41.736604Z",
     "start_time": "2024-04-13T01:03:32.351719Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def tensor_2_im(t, t_type = \"rgb\"):\n",
    "    \n",
    "    gray_tfs = T.Compose([T.Normalize(mean = [ 0.], std = [1/0.5]), T.Normalize(mean = [-0.5], std = [1])])\n",
    "    rgb_tfs = T.Compose([T.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), T.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ])])\n",
    "    \n",
    "    invTrans = gray_tfs if t_type == \"gray\" else rgb_tfs \n",
    "    \n",
    "    return (invTrans(t) * 255).detach().squeeze().cpu().permute(1,2,0).numpy().astype(np.uint8) if t_type == \"gray\" else (invTrans(t) * 255).detach().cpu().permute(1,2,0).numpy().astype(np.uint8)\n",
    "\n",
    "def visualize(data, n_ims, rows, cmap = None, cls_names = None):\n",
    "    \n",
    "    assert cmap in [\"rgb\", \"gray\"], \"Rasmni oq-qora yoki rangli ekanini aniqlashtirib bering!\"\n",
    "    if cmap == \"rgb\": cmap = \"viridis\"\n",
    "    \n",
    "    plt.figure(figsize = (20, 10))\n",
    "    indekslar = [random.randint(0, len(data) - 1) for _ in range(n_ims)]\n",
    "    for idx, indeks in enumerate(indekslar):\n",
    "        \n",
    "        im, gt = data[indeks]\n",
    "        # Start plot\n",
    "        plt.subplot(rows, n_ims // rows, idx + 1)\n",
    "        if cmap: plt.imshow(tensor_2_im(im, cmap), cmap=cmap)\n",
    "        else: plt.imshow(tensor_2_im(im))\n",
    "        plt.axis('off')\n",
    "        if cls_names is not None: plt.title(f\"GT -> {cls_names[int(gt)]}\")\n",
    "        else: plt.title(f\"GT -> {gt}\")\n",
    "            \n",
    "visualize(tr_dl.dataset, 20, 4, \"rgb\", list(classes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51204a8fcba99c19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T01:03:52.971552Z",
     "start_time": "2024-04-13T01:03:51.414435Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train loop\n",
    "def train(model, train_loader, loss_fn, optimizer, epoch=-1):\n",
    "    \"\"\"\n",
    "    Trains a model for one epoch (one pass through the entire training data).\n",
    "\n",
    "    :param model: PyTorch model\n",
    "    :param train_loader: PyTorch Dataloader for training data\n",
    "    :param loss_fn: PyTorch loss function\n",
    "    :param optimizer: PyTorch optimizer, initialized with model parameters\n",
    "    :kwarg epoch: Integer epoch to use when printing loss and accuracy\n",
    "    :returns: Accuracy score\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    loss_history = []\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(DEVICE)\n",
    "    model.train()  # Set model in training mode\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets.to(DEVICE))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Track some values to compute statistics\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        all_predictions.extend(preds.detach().cpu().tolist())\n",
    "        all_targets.extend(targets.cpu().tolist())\n",
    "\n",
    "        # Save loss every 100 batches\n",
    "        if (i % 100 == 0) and (i > 0):\n",
    "            running_loss = total_loss / (i + 1)\n",
    "            loss_history.append(running_loss)\n",
    "            # print(f\"Epoch {epoch + 1}, batch {i + 1}: loss = {running_loss:.2f}\")\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_predictions)\n",
    "    final_loss = total_loss / len(train_loader)\n",
    "    # Print average loss and accuracy\n",
    "    print(f\"Epoch {epoch + 1} done. Average train loss = {final_loss:.2f}, average train accuracy = {acc * 100:.3f}%\")\n",
    "    return acc, final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81a6ca95667a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T01:03:55.812355Z",
     "start_time": "2024-04-13T01:03:55.698278Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_fn, epoch=-1):\n",
    "    \"\"\"\n",
    "    Tests a model for one epoch of test data.\n",
    "\n",
    "    Note:\n",
    "        In testing and evaluation, we do not perform gradient descent optimization, so steps 2, 5, and 6 are not needed.\n",
    "        For performance, we also tell torch not to track gradients by using the `with torch.no_grad()` context.\n",
    "\n",
    "    :param model: PyTorch model\n",
    "    :param test_loader: PyTorch Dataloader for test data\n",
    "    :param loss_fn: PyTorch loss function\n",
    "    :kwarg epoch: Integer epoch to use when printing loss and accuracy\n",
    "\n",
    "    :returns: Accuracy score\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()  # Set model in evaluation mode\n",
    "    for i, (inputs, targets) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs.to(DEVICE))\n",
    "            loss = loss_fn(outputs, targets.to(DEVICE))\n",
    "\n",
    "            # Track some values to compute statistics\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            all_predictions.extend(preds.detach().cpu().tolist())\n",
    "            all_targets.extend(targets.cpu().tolist())\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_predictions)\n",
    "    final_loss = total_loss / len(test_loader)\n",
    "    # Print average loss and accuracy\n",
    "    print(f\"Epoch {epoch + 1} done. Average test loss = {final_loss:.4f}, average test accuracy = {acc * 100:.4f}%\")\n",
    "    return acc, final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fdb6c7428f139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T01:05:35.556102Z",
     "start_time": "2024-04-13T01:05:35.504976Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):        \n",
    "        super(CNN, self).__init__()\n",
    "        # Image size 3x225x225\n",
    "        # Number of classes = 45\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # 6x221x221\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 6x110x110\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 16x106x106\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 16x53x53\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5) # 32x49x49\n",
    "        self.lin1 = nn.Linear(32 * 49 * 49, 120)\n",
    "        self.lin2 = nn.Linear(120, 84)\n",
    "        self.lin3 = nn.Linear(84, 45)\n",
    "        self.out = nn.Softmax(dim = 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 32 * 49 * 49)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.out(self.lin3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c400b768133aee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-13T01:05:37.979926Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "NUM_EPOCHS = 10\n",
    "torch.manual_seed(0)\n",
    "model = CNN()\n",
    "optimizer = optim.Adam(model.parameters(), LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_acc, train_loss = train(model, tr_dl, loss_fn, optimizer, epoch)\n",
    "    test_acc, test_loss = test(model, ts_dl, loss_fn, epoch)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_metrics.append(train_acc)\n",
    "    test_metrics.append(test_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218cd0b9dccf988c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-12T18:46:42.118073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "xs = 1 + torch.arange(NUM_EPOCHS)\n",
    "plt.plot(xs, train_metrics, \"o-\", label=\"Train accuracy\")\n",
    "plt.plot(xs, test_metrics, \"o-\", label=\"Test accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
